{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something!\n",
      "result2:\n",
      "{   'alternative': [   {'confidence': 0.85805452, 'transcript': 'start'},\n",
      "                       {'transcript': 'start up'},\n",
      "                       {'transcript': 'start me'},\n",
      "                       {'transcript': 'start with'},\n",
      "                       {'transcript': 'stop'}],\n",
      "    'final': True}\n",
      "You said: start\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "r = sr.Recognizer()\n",
    "\n",
    "with sr.Microphone() as test:\n",
    "    print(\"Say something!\")\n",
    "    r.adjust_for_ambient_noise(test, duration=0.5)\n",
    "    audio=r.listen(test)\n",
    "\n",
    "try:\n",
    "    print(\"You said: \" + r.recognize_google(audio,language=\"en\"))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google Speech Recognition could not understand audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['close', 'clothes', 'closed', 'clo', 'clos']\n"
     ]
    }
   ],
   "source": [
    "text = r.recognize_google(audio,language=\"en\",show_all=True)\n",
    "alt = text[\"alternative\"]\n",
    "latlng = []\n",
    "for i in alt:\n",
    "    latlng.append(i[\"transcript\"])\n",
    "print(latlng)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def démarrer():\n",
    "    print(\"Démarrage\")\n",
    "\n",
    "def arrêter():\n",
    "    print(\"Arrêt\")\n",
    "\n",
    "def reconnaissance():\n",
    "    print(\"Reconnaissance vocale\")\n",
    "\n",
    "démarrage = [\"start\",\"stop\",'Scott', 'Scot', 'Stott', 'strut']\n",
    "arrêt = [\"close\",\"turn off\",'clothes', 'closed', 'clo', 'clos']\n",
    "reconnaissance_vocale = [\"recognition\",\"detection\",'depiction', 'dictation', 'protection']\n",
    "\n",
    "def check_elements(list1, list2):\n",
    "    for elem in list1:\n",
    "        if elem in list2:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_elements(latlng,démarrage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something!\n",
      "['close', 'clothes', 'closed', 'clo', 'clos']\n",
      "Arrêt\n",
      "Say something!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[185], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSay something!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     r\u001b[39m.\u001b[39madjust_for_ambient_noise(test, duration\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     audio\u001b[39m=\u001b[39mr\u001b[39m.\u001b[39;49mlisten(test)\n\u001b[1;32m      7\u001b[0m text \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mrecognize_google(audio,language\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39men\u001b[39m\u001b[39m\"\u001b[39m,show_all\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m alt \u001b[39m=\u001b[39m text[\u001b[39m\"\u001b[39m\u001b[39malternative\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/challenge_web_mining/challenge_web_mining/lib/python3.9/site-packages/speech_recognition/__init__.py:709\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[0;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[39mif\u001b[39;00m phrase_time_limit \u001b[39mand\u001b[39;00m elapsed_time \u001b[39m-\u001b[39m phrase_start_time \u001b[39m>\u001b[39m phrase_time_limit:\n\u001b[1;32m    707\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 709\u001b[0m buffer \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mread(source\u001b[39m.\u001b[39;49mCHUNK)\n\u001b[1;32m    710\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(buffer) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \u001b[39mbreak\u001b[39;00m  \u001b[39m# reached end of the stream\u001b[39;00m\n\u001b[1;32m    711\u001b[0m frames\u001b[39m.\u001b[39mappend(buffer)\n",
      "File \u001b[0;32m~/Desktop/challenge_web_mining/challenge_web_mining/lib/python3.9/site-packages/speech_recognition/__init__.py:211\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, size):\n\u001b[0;32m--> 211\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpyaudio_stream\u001b[39m.\u001b[39;49mread(size, exception_on_overflow\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Desktop/challenge_web_mining/challenge_web_mining/lib/python3.9/site-packages/pyaudio/__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_input:\n\u001b[1;32m    568\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNot input stream\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[0;32m--> 570\u001b[0m \u001b[39mreturn\u001b[39;00m pa\u001b[39m.\u001b[39;49mread_stream(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stream, num_frames,\n\u001b[1;32m    571\u001b[0m                       exception_on_overflow)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    with sr.Microphone() as test:\n",
    "        print(\"Say something!\")\n",
    "        r.adjust_for_ambient_noise(test, duration=0.5)\n",
    "        audio=r.listen(test)\n",
    "    \n",
    "    text = r.recognize_google(audio,language=\"en\",show_all=True)\n",
    "    alt = text[\"alternative\"]\n",
    "    latlng = []\n",
    "    for i in alt:\n",
    "        latlng.append(i[\"transcript\"])\n",
    "    print(latlng)\n",
    "\n",
    "    if check_elements(latlng,démarrage) == True:\n",
    "        démarrer()\n",
    "    elif check_elements(latlng,arrêt) == True:\n",
    "        arrêter()\n",
    "    elif check_elements(latlng,reconnaissance_vocale) == True:\n",
    "        reconnaissance()\n",
    "    else :\n",
    "        print(\"Commande inconnue\")\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "9269bcfef3931bc1a52df936720c9388d7237344c79f65884488093bce933461"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
