#DEBUG MODE #streamlit run --global.developmentMode=true app.py
#NORMAL MODE #streamlit run app.py

import streamlit as st #pip install streamlit
import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import plotly.express as px

import speech_recognition as sr #pip install SpeechRecognition
import cv2 as cv #pip install opencv-python
import face_recognition
import plotly.graph_objects as go

#import page Alimentation image
import pickle
import os

# import page Visage Detection
from keras.models import load_model


path = os.getcwd()
encoded_dir = str(path) + "/dossier_encoded/"
model_dir = str(path) + "/models/"
enregistrement_dir = str(path) + "/enregistrement/"

# Charger les listes depuis le fichier pickle
with open(str(encoded_dir)+'known_faces.pkl', 'rb') as f:
    known_face_encodings, known_face_names = pickle.load(f)
import test


def acceuil():
    st.title("Reconnaissance faciale et d'Ã©motions sur la webcam")
    st.header("Bienvenue sur la page de notre application !")
    st.write("Notre application propose plusieurs fonctionalitÃ©s que vous pourrez retrouvez dans les diffÃ©rents onglets.")
    st.write("Vous pourrez utiliser notre application pour dÃ©tecter les visages et les Ã©motions des personnes prÃ©sentes sur la webcam de votre ordinateur.")
    st.write("Vous pourrez Ã©galement importer ou prendre une photo afin d'alimenter notre base d'apprentissage des visages.")

################################################################################################################################################################################################################################################

def Application():
    st.title("Comment utiliser notre application")
    st.write("Pour l'utiliser, cliquez sur le bouton 'Ouvrir la webcam' ci-dessous pour ouvrir la webcam de votre ordinateur et lancer l'enregistrement la vidÃ©o.")
    st.write("Une fenÃªtre s'ouvrira et vous pourrez voir la webcam de votre ordinateur. La dÃ©tection des visages et des Ã©motions se fera en temps rÃ©el.")
    st.write("Vous pourrez Ã©galement profiter de visualisations des Ã©motions et des Ã¢ges des personnes dÃ©tectÃ©es sur la vidÃ©o.")
    st.write("Stoppez l'affichage et l'enregistrement de la webcam en cliquant sur le bouton 'Stop webcam'.")
    st.write("Vous pourrez ensuite tÃ©lÃ©charger la vidÃ©o en cliquant sur le bouton 'TÃ©lÃ©charger la vidÃ©o' (voir panneau latÃ©ral).")
    st.write("Nous souhaitions implÃ©menter la reconnaissance vocale pour lancer l'enregistrement de la vidÃ©o, mais nous n'avons pas rÃ©ussi Ã  le faire fonctionner pour toutes les fonctionnalitÃ©es.")
    st.write("Si vous cliquez sur le bouton 'Lancer la reconnaissance vocale', vous pourrez lancer l'enregistrement de la vidÃ©o en disant ''DÃ©marrer la webcam''.")
    open_webcam = st.button('Ouvrir la webcam')
    fig = go.Figure()
    def affichage_webcam():
        st.write('Camera is open')
        # Open camera with OpenCV and keep in video stream:
        video_stream = cv.VideoCapture(0)
        width = int(video_stream.get(cv.CAP_PROP_FRAME_WIDTH))
        heigth= int(video_stream.get(cv.CAP_PROP_FRAME_HEIGHT))

        fourcc = cv.VideoWriter_fourcc(*'mp4v')
        out = cv.VideoWriter(str(enregistrement_dir)+'output_0.mp4',fourcc, 3.7, (width,heigth))
        video_placeholder = st.empty()
        graphe_emotion_placeholder = st.empty()
        graphe_age_placeholder = st.empty()
        stop_button = st.button('ArrÃªter la webcam')
        while not stop_button:
            ret, frame = video_stream.read()
            if ret:
                frame = cv.flip(frame, 1)
                face_locations, face_names, face_gender, face_age, face_emotions, emotion_scores = test.detect_faces(frame, known_face_encodings, known_face_names)
                test.show_infos(frame, face_locations, face_names, face_gender, face_age, face_emotions)
                out.write(frame)

                
                #ca affiche 0 c'est bizarre 
                if face_age: 
                    #graph_elem = st.plotly_chart(fig)
                    fig_age = test.plot_age_indicator(face_age)
                    graphe_age_placeholder.plotly_chart(fig_age)
                else :
                    graphe_age_placeholder.image(path+"/emotion.jpg")

                #ca affiche 0 c'est bizarre 
                if bool(emotion_scores): 
                    #graph_elem = st.plotly_chart(fig)
                    fig_maj = test.plot_emotion_wheel(emotion_scores)
                    graphe_emotion_placeholder.plotly_chart(fig_maj)
                else :
                    graphe_emotion_placeholder.image(path+"/emotion.jpg")
                # Display the resulting image
                video_placeholder.image(frame, channels="BGR")

            if cv.waitKey(1) & 0xFF == ord('q'):
                break
        #if stop_button:
            #st.experimental_rerun()

        
        video_stream.release()
        out.release()
        cv.destroyAllWindows()
        st.write('Camera is stopped')
    if open_webcam:
        affichage_webcam()
    st.sidebar.title("Enregistrement de la vidÃ©o")
    st.sidebar.header("Vous pouvez enregistrer la vidÃ©o ou la supprimer en cliquant sur les boutons ci-dessous.")
    st.sidebar.write("Pensez bien Ã  lancer la webcam et de l'Ã©teindre avant de cliquer sur les boutons.")

    if st.sidebar.button('Supprimer la vidÃ©o'):
        st.write("La vidÃ©o va Ãªtre supprimÃ©...")
        os.remove(str(enregistrement_dir)+'output_0.mp4')
        st.experimental_rerun()

    if st.sidebar.button('Enregistrer la vidÃ©o'):
        st.write("La vidÃ©o va Ãªtre enregistrÃ©e...")
        st.experimental_rerun()

    def recognize_speech():
            r = sr.Recognizer()
            with sr.Microphone() as source:
                st.write("Parlez...")
                r.adjust_for_ambient_noise(source, duration=0.5)
                audio = r.listen(source)
                try:
                    text = r.recognize_google(audio, language='fr-FR' ,show_all=True)# change language #'en-US' # ou 'en-GB'
                    listtext = []
                    if(len(text)>0):   
                        for i in text["alternative"]:
                            listtext.append(i["transcript"])
                            
                except sr.UnknownValueError:
                    print("Je n'ai pas compris ce que vous avez dit")
                except sr.RequestError as e:
                    print("Une erreur s'est produite : {}".format(e))
        
                return listtext


    def reco_voc():
        listtext = recognize_speech()
        st.write(listtext)
        for wordlisttext in listtext:           
                
            if("dÃ©marre") in wordlisttext:
                #st.warning("start")
                if("webcam") in wordlisttext:
                        #st.warning("webcam")
                    affichage_webcam()
                    reco_voc()
                    break
                elif("reconnaissance") in wordlisttext:
                    st.warning("detection")
                    break
                elif("enregistrement") in wordlisttext:
                    st.warning("recording")
                    break
                    
            elif("arrÃªte") in wordlisttext:
                #st.warning("stop")
                if("webcam") in wordlisttext:
                    stop_webcamp()
                    break
                elif("reconnaissance") in wordlisttext:
                    st.warning("detection")
                    break
                elif("enregistrement") in wordlisttext:
                    st.warning("recording")
                    break

    if st.button("Lancer la reconnaissance vocale"):
        reco_voc() 
   
################################################################################################################################################################################################################################################
def alimentation():
    st.title("Alimentation des Images")
    st.write("Vous pouvez ajouter des images dans le dossier /etu pour alimenter notre base.")
    st.write("Vous pouvez prendre une photo avec votre webcam qui sera importer en local dans le dossier /etu.")
    st.write("Il vous faudra ensuite importer la photo pour la transformer et l'ajouter Ã  notre base.")

    path = os.getcwd()
    encoded_dir = str(path) + "/dossier_encoded/"
    etu_dir = str(path) + "/etu/"


    st.header(" Prendre une photo avec la Webcam :")


    # Open Webcam
    user_input = st.text_input("Entrez votre prÃ©nom et nom si vous souhaitez prendre une photo : ")
    if st.button("Take a photo with webcam"):
        if len(user_input) == 0:
            # check if user input his first and last name to create the image name
            st.warning("Veuillez entrer votre prÃ©nom et nom !")
        else :
            # registred photo in etu folder
            cam = cv.VideoCapture(0)
            ret, frame = cam.read()
            cv.imwrite(str(etu_dir) + str(user_input) + ".jpeg", frame)
            st.warning("Photo EnregistrÃ©e dans le dossier /etu !")
       
    # selection of the image on streamlit
    st.header(" Importer une photo :")
    image_file = st.file_uploader("SÃ©lectionner une image", type='jpeg')

    # load list of images from pickle file
    with open(str(encoded_dir)+'known_faces.pkl', 'rb') as f:
        known_face_encodings, known_face_names = pickle.load(f)

    # add image and name in each list 
    if image_file is not None:
        image = face_recognition.load_image_file(image_file)
        try : 
            face_encoding = face_recognition.face_encodings(image)[0]#
            known_face_encodings.append(face_encoding)
            known_face_names.append(image_file.name.split(".")[0])
            st.write("Photo bien enrÃ©gistrÃ©e dans la base !")
        except:
            st.warning("Attention Visage non dÃ©tectÃ©. Utilise une autre photo")
            os.remove(etu_dir + user_input + ".jpeg")


    # registred list in pickle file
    with open(str(encoded_dir)+'known_faces.pkl', 'wb') as f:
        pickle.dump((known_face_encodings, known_face_names), f)
    
################################################################################################################################################################################################################################################
def reconnaissance_vocale():
    st.title("Reconnaissance vocale")
    st.write("A l'origine nous souhaitions utiliser la reconnaissance vocale pour piloter notre application.")
    st.write("Malheureusement nous n'avons pas rÃ©ussi Ã  faire fonctionner la reconnaissance vocale pour toutes les fonctionnalitÃ©es.")
    st.write("Dans cet onglet vous pourrez tester les diffÃ©rentes fonctions vocales que nous avions mis en place.")
    st.write("Testez par exemple '' DÃ©marrer la dÃ©tection '' ou '' ArrÃªter l'enregistrement ''")
    def recognize_speech():
        r = sr.Recognizer()
        with sr.Microphone() as source:
            st.write("Parlez...")
            r.adjust_for_ambient_noise(source, duration=0.5)
            audio = r.listen(source)
            try:
                text = r.recognize_google(audio, language='fr-FR' ,show_all=True)# change language #'en-US' # ou 'en-GB'
                listtext = []
                if(len(text)>0):   
                    for i in text["alternative"]:
                        listtext.append(i["transcript"])
                        
            except sr.UnknownValueError:
                print("Je n'ai pas compris ce que vous avez dit")
            except sr.RequestError as e:
                print("Une erreur s'est produite : {}".format(e))
    
            return listtext             
     
    while True:
        listtext = recognize_speech()
        st.write(listtext)
        
        for wordlisttext in listtext:              
            if("dÃ©marre") in wordlisttext:
                #st.warning("start")
                if("webcam") in wordlisttext:
                    st.warning("DÃ©mmarage de la webcam")
                    break
                elif("reconnaissance") in wordlisttext:
                    st.warning("DÃ©marrage de la detection")
                    break
                elif("enregistrement") in wordlisttext:
                    st.warning("DÃ©mmarage de l'enregistrement")
                    break
                
            elif("arrÃªte") in wordlisttext:
                #st.warning("stop")
                if("webcam") in wordlisttext:
                    st.warning("ArrÃªt de la webcam")
                    break
                elif("reconnaissance") in wordlisttext:
                    st.warning("ArrÃªt de la detection")
                    break
                elif("enregistrement") in wordlisttext:
                    st.warning("ArrÃªt de l'enregistrement")
                    break
       
##################################### MENU ################################################################################################################################################
# page list
pages = {
    "Acceuil": acceuil,
    "DÃ©tection de visage et d'Ã©motions": Application,
    "Alimentation des Images": alimentation,
    "Reconnaissance vocale": reconnaissance_vocale
}

# Navigation bar
st.sidebar.title("Menu ðŸ“Š")
selection = st.sidebar.radio("Aller Ã ", list(pages.keys()))

# Display Select Page
page = pages[selection]
page()